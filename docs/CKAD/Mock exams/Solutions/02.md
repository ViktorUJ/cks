---
custom_edit_url: null
---

# 02

Solutions for CKAD Mock exam #02

[Video Solution](https://www.youtube.com/watch?v=_0nX68vil-A)

## 01

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
k get ns  jellyfish

k create secret generic secret1  -n jellyfish --from-literal key1=value1

k get po -n jellyfish

k get po -n jellyfish -o yaml  >1.yaml

k delete -f 1.yaml
```

```yaml
# vim 1.yaml
apiVersion: v1
items:
- apiVersion: v1
  kind: Pod
  metadata:
    annotations:
      cni.projectcalico.org/containerID: cdf2830539800a7ed95df197ec8dfd9766589f60f1d27a43513a4f006b6af0e0
      cni.projectcalico.org/podIP: 10.0.77.195/32
      cni.projectcalico.org/podIPs: 10.0.77.195/32
      kubectl.kubernetes.io/last-applied-configuration: |
        {"apiVersion":"v1","kind":"Pod","metadata":{"annotations":{},"labels":{"run":"app1"},"name":"app1","namespace":"jellyfish"},"spec":{"containers":[{"image":"viktoruj/ping_pong","name":"app"}]}}
    creationTimestamp: "2024-02-21T05:39:44Z"
    labels:
      run: app1
    name: app1
    namespace: jellyfish
    resourceVersion: "1949"
    uid: 0d02da57-635e-44da-be03-d952a3ee85f2
  spec:
    containers:
    - image: viktoruj/ping_pong
      imagePullPolicy: Always
      name: app
      resources: {}
      terminationMessagePath: /dev/termination-log
      terminationMessagePolicy: File
      volumeMounts:
      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount
        name: kube-api-access-rjv5n
        readOnly: true
      env:                                     #add it
      - name: PASSWORD                         #add it
        valueFrom:                             #add it
          secretKeyRef:                        #add it
            name: secret1                      #add it
            key: key1                          #add it

    dnsPolicy: ClusterFirst
    enableServiceLinks: true
    nodeName: ip-10-2-7-44
    preemptionPolicy: PreemptLowerPriority
    priority: 0
    restartPolicy: Always
    schedulerName: default-scheduler
    securityContext: {}
    serviceAccount: default
    serviceAccountName: default
    terminationGracePeriodSeconds: 30
    tolerations:
    - effect: NoExecute
      key: node.kubernetes.io/not-ready
      operator: Exists
      tolerationSeconds: 300
    - effect: NoExecute
      key: node.kubernetes.io/unreachable
      operator: Exists
      tolerationSeconds: 300
    volumes:
    - name: kube-api-access-rjv5n
      projected:
        defaultMode: 420
        sources:
        - serviceAccountToken:
            expirationSeconds: 3607
            path: token
        - configMap:
            items:
            - key: ca.crt
              path: ca.crt
            name: kube-root-ca.crt
        - downwardAPI:
            items:
            - fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
              path: namespace
kind: List
metadata:
  resourceVersion: ""
```

```sh
k apply  -f 1.yaml
```

```sh
$ k get po -n jellyfish

NAME   READY   STATUS    RESTARTS   AGE
app1   1/1     Running   0          15m
```

```sh
k exec app1  -n jellyfish -- sh -c 'echo $PASSWORD'
```

## 02

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
k get ns  rnd

k create ns rnd

k create cronjob  cron-job1 --image viktoruj/ping_pong:alpine --schedule "*/15 * * * *" -n rnd -o yaml --dry-run=client   >2.yaml
```

```sh
# vim 2.yaml

apiVersion: batch/v1
kind: CronJob
metadata:
  creationTimestamp: null
  name: cron-job1
  namespace: rnd
spec:
  jobTemplate:
    metadata:
      creationTimestamp: null
      name: cron-job1
    spec:
      template:
        metadata:
          creationTimestamp: null
        spec:
          containers:
          - image: viktoruj/ping_pong:alpine
            name: cron-job1
            command: ["echo","Hello from CKAD mock"]           # add it
            resources: {}
          restartPolicy: OnFailure
      backoffLimit: 4                                         # add it
      completions: 3                                          # add it
  schedule: '*/15 * * * *'
  concurrencyPolicy: Forbid                                    # add it
status: {}
```

```sh
k apply -f 2.yaml

k get cronjob -n rnd
```

## 03

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
k rollout history deployment my-deployment  -n baracuda

k rollout undo deployment my-deployment --to-revision=1 -n baracuda

k scale  deployments.apps my-deployment  -n baracuda  --replicas 3
```

## 04

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
k get ns  shark

k create ns shark

k create deployment  shark-app -n shark --image viktoruj/ping_pong --port 8080 -o yaml --dry-run=client  > 4.yaml
```

```yaml
# vim 4.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: shark-app
  name: shark-app
  namespace: shark
spec:
  replicas: 1
  selector:
    matchLabels:
      app: shark-app
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: shark-app
    spec:
      containers:
      - image: viktoruj/ping_pong
        name: ping-pong-cjnt8
        env:                                 # add it
         - name: ENV1                        # add it
           value: "8080"                     # add it
        ports:
        - containerPort: 8080
        resources: {}
status: {}
```

```sh
k apply -f 4.yaml
k get po -n shark
```

## 05

```sh
cd /var/work/5/

podman build . -t ckad:0.0.1

podman save --help

podman save --format oci-archive -o ckad.tar ckad:0.0.1
```

## 06

https://kubernetes.io/docs/tasks/configure-pod-container/security-context/

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
k edit deployment  sword-app  -n  swordfish
```

```sh
#
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"apps/v1","kind":"Deployment","metadata":{"annotations":{},"creationTimestamp":null,"labels":{"app":"sword-app"},"name":"sword-app","namespace":"swordfish"},"spec":{"replicas":1,"selector":{"matchLabels":{"app":"sword-app"}},"strategy":{},"template":{"metadata":{"creationTimestamp":null,"labels":{"app":"sword-app"}},"spec":{"containers":[{"image":"viktoruj/ping_pong:alpine","name":"app","resources":{}}]}}},"status":{}}
  creationTimestamp: "2024-02-28T05:32:13Z"
  generation: 1
  labels:
    app: sword-app
  name: sword-app
  namespace: swordfish
  resourceVersion: "1821"
  uid: bbd06535-282a-45a2-9c13-388cd916f879
spec:
  progressDeadlineSeconds: 600
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: sword-app
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: sword-app
    spec:
      containers:
      - image: viktoruj/ping_pong:alpine
        imagePullPolicy: IfNotPresent
        name: app
        resources: {}
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        securityContext:
          allowPrivilegeEscalation: false                   # add it
          runAsUser: 5000                                   # add it
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext: {}
      terminationGracePeriodSeconds: 30
```

## 07

```sh
kubectl config use-context cluster1-admin@cluster1
```

Check app

```sh
k get po -n meg
```

```sh
NAME                       READY   STATUS    RESTARTS   AGE
meg-app-5957b8b4fb-7tv5s   1/1     Running   0          9m57s
```

```sh
k exec {pod_name} -n meg -- curl 127.0.0.0
```

```sh
 k exec meg-app-5957b8b4fb-7tv5s -n meg  -- curl 127.0.0.0
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0Server Name: megApp
URL: http://127.0.0.0/
Client IP: 127.0.0.1
Method: GET
Protocol: HTTP/1.1
Headers:
User-Agent: curl/8.5.0
Accept: */*
100   139  100   139    0     0  20002      0 --:--:-- --:--:-- --:--:-- 23166
```

Check service

```sh
k get svc -n meg

k exec {pod_name} -n meg -- curl meg-service
```

```sh
$ k exec meg-app-5957b8b4fb-7tv5s -n meg -- curl meg-service
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0
curl: (7) Failed to connect to meg-service port 80 after 0 ms: Couldn't connect to server
command terminated with exit code 7
```

```sh
k get po -n meg --show-labels
```

```text
NAME                       READY   STATUS    RESTARTS   AGE   LABELS
meg-app-5957b8b4fb-7tv5s   1/1     Running   0          14m   app=meg-app,pod-template-hash=5957b8b4fb
```

Fix the service

```sh
k edit svc  meg-service -n meg
```

```yaml
apiVersion: v1
kind: Service
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"v1","kind":"Service","metadata":{"annotations":{},"creationTimestamp":null,"labels":{"app":"meg-service"},"name":"meg-service","namespace":"meg"},"spec":{"ports":[{"port":80,"protocol":"TCP","targetPort":80}],"selector":{"app":"megapp"},"type":"ClusterIP"},"status":{"loadBalancer":{}}}
  creationTimestamp: "2024-03-02T10:06:04Z"
  labels:
    app: meg-service
  name: meg-service
  namespace: meg
  resourceVersion: "615"
  uid: ad2edd84-efa9-4960-a4af-015384c05ad9
spec:
  clusterIP: 10.104.169.81
  clusterIPs:
  - 10.104.169.81
  internalTrafficPolicy: Cluster
  ipFamilies:
  - IPv4
  ipFamilyPolicy: SingleStack
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: meg-app                   # update it
  sessionAffinity: None
  type: ClusterIP
status:
  loadBalancer: {}
```

Check service

```sh
k exec {pod_name} -n -- curl meg-service
```

```sh
 k exec meg-app-5957b8b4fb-7tv5s -n meg -- curl meg-service
  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                 Dload  Upload   Total   Spent    Left  Speed
100   141  100   141    0     0   110k      0 --:--:-- --:--:-- --:--:--  137k
Server Name: megApp
URL: http://meg-service/
Client IP: 10.2.30.2
Method: GET
Protocol: HTTP/1.1
Headers:
User-Agent: curl/8.5.0
Accept: */*


```

Check ingress

```sh
curl http://ckad.local:30102/app
```

```sh
 curl http://ckad.local:30102/app
<html>
<head><title>404 Not Found</title></head>
<body>
<center><h1>404 Not Found</h1></center>
<hr><center>nginx</center>
</body>
</html>
```

```sh
k edit  ing -n meg
```

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"networking.k8s.io/v1","kind":"Ingress","metadata":{"annotations":{"nginx.ingress.kubernetes.io/rewrite-target":"/"},"name":"meg","namespace":"meg"},"spec":{"rules":[{"http":{"paths":[{"backend":{"service":{"name":"meg-service","port":{"number":808}}},"path":"/app","pathType":"Prefix"}]}}]}}
    nginx.ingress.kubernetes.io/rewrite-target: /
  creationTimestamp: "2024-03-02T10:06:04Z"
  generation: 1
  name: meg
  namespace: meg
  resourceVersion: "623"
  uid: 760c846a-8ffc-49d9-af73-ec37b049e095
spec:
  rules:
  - http:
      paths:
      - backend:
          service:
            name: meg-service
            port:
              number: 80                       # Update it from 808
        path: /app
        pathType: Prefix
status:
  loadBalancer: {}

```

Check ing

```sh
$ curl http://ckad.local:30102/app
```

```sh
$ curl http://ckad.local:30102/app
Server Name: megApp
URL: http://ckad.local:30102/
Client IP: 10.0.201.65
Method: GET
Protocol: HTTP/1.1
Headers:
X-Request-Id: 7d7ab6af29f7ff5d95f6df86153bb287
X-Forwarded-For: 10.2.4.4
X-Forwarded-Host: ckad.local:30102
X-Forwarded-Scheme: http
X-Scheme: http
X-Real-Ip: 10.2.4.4
X-Forwarded-Port: 80
X-Forwarded-Proto: http
User-Agent: curl/7.68.0
Accept: */*
```

## 08

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
k get networkpolicies -n tuna
```

```text
NAME                   POD-SELECTOR   AGE
allow-web-app-db       app=mysql-db   15m
default-deny-ingress   <none>         15m
```

```sh
k get networkpolicies allow-web-app-db  -n tuna  -o yaml
```

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  annotations:
    kubectl.kubernetes.io/last-applied-configuration: |
      {"apiVersion":"networking.k8s.io/v1","kind":"NetworkPolicy","metadata":{"annotations":{},"name":"allow-web-app-db","namespace":"tuna"},"spec":{"ingress":[{"from":[{"namespaceSelector":{"matchLabels":{"kubernetes.io/metadata.name":"tuna"}},"podSelector":{"matchLabels":{"type":"backend"}}}]}],"podSelector":{"matchLabels":{"app":"mysql-db"}},"policyTypes":["Ingress"]}}
  creationTimestamp: "2024-03-02T13:07:09Z"
  generation: 1
  name: allow-web-app-db
  namespace: tuna
  resourceVersion: "666"
  uid: d05891ba-c6ed-415b-a7ed-e8f0ae14e7f0
spec:
  ingress:
  - from:
    - namespaceSelector:
        matchLabels:
          kubernetes.io/metadata.name: tuna
      podSelector:
        matchLabels:
          type: backend
  podSelector:
    matchLabels:
      app: mysql-db
  policyTypes:
  - Ingress
```

```sh
k get po -n tuna web-app   -o yaml > 8.yaml
```

```sh
vim 8.yaml
```

```yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    run: web-app
    type: backend                     # add this label
  name: web-app
  namespace: tuna
spec:
  containers:
  - image: viktoruj/ping_pong:alpine
    imagePullPolicy: IfNotPresent
    name: web-app
...
```

```sh
k delete -f 8.yaml
k apply -f 8.yaml

```

Check connection

```sh
k exec web-app  -n tuna  -- curl mysql-db:3306
```

## 09

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
k scale deployment main-app -n salmon  --replicas 7

k get  deployment main-app -n salmon  -o yaml   > 9.yaml
```

```yaml
# vim 9.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  annotations:
  labels:
    app: main-app
  name: main-app-v2                                 # update it
  namespace: salmon
spec:
  progressDeadlineSeconds: 600
  replicas: 3                                       # update it
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: main-app
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: main-app
    spec:
      containers:
      - env:
        - name: SERVER_NAME
          value: appV2                              # update it
        - name: SRV_PORT
          value: "80"
        image: viktoruj/ping_pong:latest            # update it
        imagePullPolicy: IfNotPresent
        name: app
        ports:
        - containerPort: 80
          protocol: TCP
        resources: {}
```

```sh
k apply -f 9.yaml
k get po   -n salmon  --no-headers |wc -l
```

```text
10
```

```sh
curl  http://ckad.local:30102/main-app -s  | grep 'Server Name'
curl  http://ckad.local:30102/main-app -s  | grep 'Server Name'
curl  http://ckad.local:30102/main-app -s  | grep 'Server Name'
```

```sh
ubuntu@worker:~> curl  http://ckad.local:30102/main-app -s  | grep 'Server Name'
Server Name: appV1
ubuntu@worker:~> curl  http://ckad.local:30102/main-app -s  | grep 'Server Name'
Server Name: appV1
ubuntu@worker:~> curl  http://ckad.local:30102/main-app -s  | grep 'Server Name'
Server Name: appV1
ubuntu@worker:~> curl  http://ckad.local:30102/main-app -s  | grep 'Server Name'
Server Name: appV2
ubuntu@worker:~> curl  http://ckad.local:30102/main-app -s  | grep 'Server Name'
Server Name: appV2
```

## 10

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
k get no -l node_name=node_2
# ssh to worker node
sudo mkdir /pv/analytics -p
sudo chmod  777 -R /pv/analytics
exit
```

```yaml
# vim 10.yaml
---
apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv-analytics
  labels:
    type: local
spec:
  storageClassName: manual
  capacity:
    storage: 100Mi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/pv/analytics"
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc-analytics
spec:
  storageClassName: manual
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Mi
---
apiVersion: v1
kind: Pod
metadata:
  name: analytics
spec:
  volumes:
    - name: task-pv-storage
      persistentVolumeClaim:
        claimName: pvc-analytics
  nodeSelector:
    node_name: node_2
  containers:
    - name: task-pv-container
      image: busybox
      command: ["sleep","60000"]
      volumeMounts:
        - mountPath: "/pv/analytics"
          name: task-pv-storage
```

```sh
k apply -f 10.yaml
```

## 11

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
k create ns dev-db
k create secret -n dev-db generic dbpassword --from-literal pwd=my-secret-pwd
k run db-pod --namespace dev-db --labels type=db --image mysql:8.0 --dry-run=client -o yaml >11.yaml
```

Edit definition file and add env variable to have

```yaml
#  vim  11.yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    type: db
  name: db-pod
  namespace: dev-db
spec:
  containers:
  - image: mysql:8.0
    name: db-pod
    env:
    - name: MYSQL_ROOT_PASSWORD
      valueFrom:
        secretKeyRef:
          name: dbpassword
          key: pwd
```

Apply the changes:

```sh
k  apply -f 11.yaml
```

## 12

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
k get po -A | grep 'app-xyz3322'
```

```text
default         app-xyz3322                                 1/1     Running   0          26m
```

```sh
k logs pods/app-xyz3322
k logs pods/app-xyz3322 > /opt/logs/app-xyz123.log
```

## 13

```sh
kubectl config use-context cluster1-admin@cluster1

k create ns web-ns

k run nginx1233 --namespace web-ns --image nginx --dry-run=client -o yaml > 13.yaml
```

Edit manifest by configuring liveness probes

```yaml
# vim 13.yaml
apiVersion: v1
kind: Pod
metadata:
  labels:
    run: nginx1233
  name: nginx1233
  namespace: web-ns
spec:
  containers:
  - image: nginx
    name: nginx1233
    livenessProbe:
      exec:
        command:
        - ls
        - /var/www/html/
      initialDelaySeconds: 10
      periodSeconds: 60
```

```sh
k apply -f 13.yaml
```

## 14

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update


helm install prom prometheus-community/kube-prometheus-stack \
  --namespace monitoring --create-namespace
```

## 15

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
k get ns team-elephant

k create ns team-elephant

k create serviceaccount pod-sa --namespace team-elephant

k create role pod-sa-role -n team-elephant --resource pods --verb list,get

k create rolebinding  pod-sa-roleBinding -n team-elephant --role pod-sa-role --serviceaccount team-elephant:pod-sa

k run pod-sa --image viktoruj/cks-lab -n team-elephant  -o yaml --dry-run=client  --command sleep 60000  >13.yaml
```

```yaml
# vim 15.yaml

apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: pod-sa
  name: pod-sa
  namespace: team-elephant
spec:
  serviceAccountName: pod-sa   #    add it
  containers:
  - command:
    - sleep
    - "60000"
    image: viktoruj/cks-lab
    name: pod-sa
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}
```

```sh
k apply -f 15.yaml

k get po -n team-elephant
```

```sh
k  auth can-i list  pods --as=system:serviceaccount:team-elephant:pod-sa --namespace=team-elephant

yes

k  auth can-i delete  pods --as=system:serviceaccount:team-elephant:pod-sa --namespace=team-elephant

no
```

```sh
# check from pod  (not nesesary )
kubectl exec pod-sa  -n team-elephant  --context cluster1-admin@cluster1  -- sh -c 'curl  GET https://kubernetes.default/api/v1/namespaces/team-elephant/pods/  -s -H "Authorization: Bearer $(cat /run/secrets/kubernetes.io/serviceaccount/token)" -k'
```

## 16

```sh
kubectl config use-context cluster1-admin@cluster1
```

```yaml
#k edit deployment legacy-app -n legacy
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: legacy-app
  name: legacy-app
  namespace: legacy
spec:
  replicas: 1
  selector:
    matchLabels:
      app: legacy-app
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: legacy-app
    spec:
      volumes:                                                                  # add it
        - emptyDir:                                                             # add it
            sizeLimit: 500Mi                                                    # add it
          name: logs                                                            # add it
      containers:
      - image: viktoruj/ping_pong
        name: app1
        volumeMounts:                                                            # add it
        - mountPath: /log                                                        # add it
          name: logs                                                             # add it
        env:
        - name: SERVER_NAME
          value: "app1"
        - name: SRV_PORT
          value: "8081"
        - name: METRIC_PORT
          value: "9092"
        - name: LOG_PATH
          value: /log/logs1.txt
        - name: ENABLE_OUTPUT
          value: "false"
      - image: viktoruj/ping_pong
        name: app2
        volumeMounts:                                                             # add it
        - mountPath: /log                                                         # add it
          name: logs                                                              # add it
        env:
        - name: SERVER_NAME
          value: "app2"
        - name: SRV_PORT
          value: "8082"
        - name: METRIC_PORT
          value: "9092"
        - name: LOG_PATH
          value: /log/logs2.txt
        - name: ENABLE_OUTPUT
          value: "false"
      - image: viktoruj/cks-lab                                                    # add it
        name: log                                                                  # add it
        command: ["tail","-f","-n","100", "/log/logs1.txt","-f","/log/logs2.txt"]  # add it
        volumeMounts:                                                              # add it
        - mountPath: /log                                                          # add it
          name: logs                                                               # add it
```

```sh
# check logs

k exec  checker -n legacy -- sh -c 'curl legacy-app:8081/test_app1'
k exec  checker -n legacy -- sh -c 'curl legacy-app:8082/test_app2'

k logs  -l app=legacy-app  -n legacy  -c log
```

## 17

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
k logs  -n app-x -l app_name=xxx >/opt/17/17.log

cat /opt/17/17.log
```

## 18

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
# get pod malifest
k get po -n app-y -o yaml  > 9_pod.yaml

# create deployment template

k create  deployment deployment-app-y -n app-y --image xxx -o yaml --dry-run=client >9_deloyment.yaml

# copy from 9_pod.yaml  to 9_deloyment.yaml  configuration
```

```yaml
# vim 9_deloyment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: deployment-app-y
  name: deployment-app-y
  namespace: app-y
spec:
  replicas: 1
  selector:
    matchLabels:
      app: deployment-app-y
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: deployment-app-y
    spec:
      containers:
      - env:
        - name: SERVER_NAME
          value: app-y
        image: viktoruj/ping_pong:alpine
        imagePullPolicy: IfNotPresent
        name: app
        securityContext:                                 # add it
          allowPrivilegeEscalation: false                                          # add it
          privileged : false                             # add it
```

```sh
k apply -f 9_deloyment.yaml

k get po,deployment -n app-y
```

## 19

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
# k get ns  app-z
Error from server (NotFound): namespaces "app-z" not found
```

```sh
k create ns app-z

k create  configmap config -n app-z --from-file /var/work/19/ingress_nginx_conf.yaml

k get configmaps  config -n  app-z -o yaml

k create  deployment  app-z -n app-z --image  viktoruj/ping_pong:alpine -o yaml --dry-run=client > 19.yaml
```

```yaml
# vim 19.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: app-z
  name: app-z
  namespace: app-z
spec:
  replicas: 1
  selector:
    matchLabels:
      app: app-z
  strategy: {}
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: app-z
    spec:
      volumes:
       - name: config-volume
         configMap:
           name: config
      containers:
      - image: viktoruj/ping_pong:alpine
        name: ping-pong-9qnmz
        volumeMounts:
         - name: config-volume
           mountPath: "/appConfig"
```

```sh
k apply -f 19.yaml
k get po -n app-z
k exec {pod_name}  -n app-z -- cat  /appConfig/ingress_nginx_conf.yaml
```

```yaml
# k exec app-z-66df5d84d9-2c44w  -n app-z -- cat  /appConfig/ingress_nginx_conf.yaml
controller:
  service:
    type: NodePort
    nodePorts:
      http: 30102
      https: 31139
  ingressClass:
    create: true
    name: nginx
    setAsDefaultIngress: true

```

## 20

```sh
kubectl config use-context cluster1-admin@cluster1
```

```sh
# k get ns  app-20
Error from server (NotFound): namespaces "app-20" not found
```

```sh
k create ns  app-20

k create deployment app -n app-20 --image viktoruj/ping_pong:alpine -o yaml  --dry-run=client >20.yaml
```

```yaml
# vim 20.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: app
  name: app
  namespace: app-20
spec:
  replicas: 1
  selector:
    matchLabels:
      app: app
  template:
    metadata:
      creationTimestamp: null
      labels:
        app: app
    spec:
      volumes:                                                                  # add it
       - name: cache-volume                                                     # add it
         emptyDir:                                                              # add it
            sizeLimit: 5Mi                                                      # add it
      initContainers:                                                           # add it
      - name: init                                                              # add it
        image: viktoruj/ping_pong:alpine                                        # add it
        command: ["sh", "-c","echo 'hello from init' >/configs/app.config"]     # add it
        volumeMounts:                                                           # add it
        - mountPath: /configs                                                   # add it
          name: cache-volume                                                    # add it

      containers:
      - image: viktoruj/ping_pong:alpine
        name: app                                                               # update it
        volumeMounts:                                                           # add it
        - mountPath: /configs                                                   # add it
          name: cache-volume                                                    # add it
```

```sh
k apply -f 20.yaml
```

```sh
k get po -n app-20

k exec  {pod}   -n app-20  -- cat /configs/app.config
```
